# Founder Copilot (Responses API)

An AI-powered assistant for startup founders, migrated from OpenAI's Assistants API to the Responses API. This project maintains all the functionality of the original founder-copilot but uses the new Responses API instead of the deprecated Assistants API.

## Migration Status

This project is a migration from the Assistants API to the Responses API. Key changes:

- **Assistants â†’ System Prompts**: Instead of creating assistant objects, we use system prompts with Chat Completions
- **Threads â†’ Conversation History**: Instead of thread management, we maintain conversation history in memory/database
- **file_search tool â†’ Vector Search**: Instead of using the file_search tool, we perform vector search ourselves and inject context
- **code_interpreter tool â†’ Function Calling**: Instead of code_interpreter, we use function calling with Python execution

## Features

- ğŸ¤– **AI Assistant** - Powered by GPT-4 with retrieval-augmented generation (RAG)
- ğŸ¯ **Multi-Assistant Routing** - Intelligent routing to specialized assistants (Tech, Marketing, Investor)
- ğŸ“š **Knowledge Base** - Vector store containing startup resources (YC advice, checklists, scenarios)
- ğŸ’¬ **Modern Chat Interface** - Beautiful, responsive web UI with structured responses
- âš¡ **Real-Time Streaming** - Server-Sent Events (SSE) for live response streaming with visual indicators
- ğŸ” **File Search** - Automatic retrieval of relevant information from knowledge base
- ğŸ“ **Source Citations** - Automatic extraction and display of source files with quotes
- ğŸ§® **Code Interpreter** - Python code execution for founder analytics, calculations, and visualizations
- ğŸ“ˆ **Chart Display** - Automatic extraction and display of charts/visualizations generated by code execution
- ğŸ“ **File Upload** - Upload CSV, Excel, or other files for analysis and visualization
- ğŸ“‹ **Product Card System** - Automatic extraction and management of product context for deictic references
- ğŸ”„ **File Persistence** - Automatic re-attachment of files across follow-up questions in data analysis flows
- ğŸ“Š **Metrics Dashboard** - Track token usage, latency (P95), and request statistics
- ğŸš¦ **Rate Limiting** - Redis-based rate limiting to protect API endpoints
- ğŸ³ **Docker Support** - Easy deployment with Docker Compose

## Setup

1. **Create `.env` file**:
   ```bash
   OPENAI_API_KEY=your_api_key_here
   OPENAI_MODEL=gpt-4o
   REDIS_URL=redis://localhost:6379/0
   ```

2. **Build and run with Docker**:
   ```bash
   docker compose up -d --build
   ```

3. **Access the application**:
   - Web Interface: http://localhost:8000
   - Metrics Dashboard: http://localhost:8000/metrics

## Migration Notes

For detailed information about migrating from Assistants API to Responses API, see:
- [OpenAI Migration Guide](https://platform.openai.com/docs/assistants/migration)
- Original project: `founder-copilot` (uses Assistants API)

## File & Image Extraction

This project implements a robust system for extracting and serving files and images from Responses API responses, particularly those generated by code_interpreter.

### Image Extraction Methods

The system extracts images from Responses API responses using multiple strategies:

1. **Direct Output Image Extraction**: Images are extracted from `output_image` content types in `response.output[].content[]`:
   ```python
   # Structure: {"type": "output_image", "image": {"file_id": "file-abc123"}}
   if content_type == "output_image":
       file_id = content_item["image"]["file_id"]
   ```

2. **Container File Citation Extraction**: Images are extracted from `container_file_citation` annotations in text content:
   ```python
   # Annotations contain: {"type": "container_file_citation", "file_id": "...", "container_id": "...", "filename": "chart.png"}
   if ann_type == "container_file_citation" and filename.endswith(('.png', '.jpg', '.jpeg')):
       images.append({"file_id": file_id, "container_id": container_id})
   ```

3. **Fallback Text Parsing**: As a fallback, file IDs are parsed from response text using regex patterns (e.g., `file-abc123` or `sandbox:/mnt/data/file-abc123.png`).

### Container File Retrieval

Container files (images generated by code_interpreter) are retrieved using direct HTTP calls to the Containers API endpoint, as the SDK doesn't support container file downloads:

```python
# Direct HTTP call to: /v1/containers/{container_id}/files/{file_id}/content
url = f"{base_url}/containers/{container_id}/files/{file_id}/content"
req = Request(url)
req.add_header("Authorization", f"Bearer {api_key}")
response = urlopen(req, timeout=60.0)
return response.read()
```

### Image Serving Endpoints

Images are served on-demand via API endpoints:

- **Regular Files**: `GET /api/file/{file_id}` - Downloads files from OpenAI Files API
- **Container Files**: `GET /api/container-file/{container_id}/{file_id}` - Downloads container files via direct HTTP

The frontend receives image metadata (file_id, container_id, url) and displays images by fetching them from these endpoints, avoiding the need to download and store images server-side.

## License

MIT

